{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9510e099a545101efbaa0cf7733c91cc",
     "grade": false,
     "grade_id": "cell-91ecdd51e335450e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import scipy.signal\n",
    "import os\n",
    "# helpers.py is one level up in the directory structure so we need to tell Python were to find it\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import helpers\n",
    "local_data_folder = os.path.join(helpers.dataset_folder, \"week3\", \"inpainting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfdd088b4fb560c4fd1b5a4e4c56ae2a",
     "grade": false,
     "grade_id": "cell-8315cc1f829f08c5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Pull-Push algorithm\n",
    "\n",
    "The Pull-Push algorithm is a simple inpainting technique that fills missing part of an image by propagating mean (average) values from neighboring valid regions. The algorithm proceeds in two phases. First, an image pyramid is build by aggregating valid information from the image (pull). Second, the information from the top of the pyramid is propagated down and interpolated into the previously empty bins (push). This results in each image pixel receiving the information from an image area proportional to the size of the hole as larger holes will generally be filled in higher levels of the pull-push pyramid representing mean of a larger portion of the image. While the technique cannot resolve any higher-order statistical properties (gradients, curvatures,...), it provides a visually continuous transition between the original image content and the smooth inpainted regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "014ab361bcc259f1224adbda53c8d093",
     "grade": false,
     "grade_id": "cell-8cf1d83c8ef069f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 4 (3 points)\n",
    "\n",
    "First, we will implement a step of the pull phase which generates a new image of half the original size.\n",
    "\n",
    "Implement a function that aggregates information from an image $\\mathbf{I^i} \\in \\mathcal{R}^{H \\times W\\times 3}$ into a new image $\\mathbf{I^{i+1}} \\in \\mathcal{R}^{H/2 \\times W/2 \\times 3}$. Each pixel of $\\mathbf{I^{i+1}}$ contains a mean value of valid pixels in a corresponding $2\\times2$ region of $\\mathbf{I^i}$. A pixel is valid if the weight $M^i \\in \\{0,1\\}^{H \\times W\\times 3}$ = 1 at a given location. \n",
    "You can assume that $W = H$ and $W = 2^{k}$ for $k\\in\\mathcal{N}$ (that is $\\mathbf{I^i}$ is a square image with sides divisible by two).\n",
    "\n",
    "As a second output return new pixel weights\n",
    "$$\n",
    "M^{i+1} \\in \\{0,1\\}^{H/2 \\times W/2} =\n",
    "\\begin{cases}\n",
    "    1,             & \\text{if } \\text{at least one of the $2\\times2$ inputs is valid} \\\\\n",
    "    0,             & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Set $\\mathbf{I}^{i+1} = \\mathbf{0}$ where $M^{i+1} = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfcf1de45e020c0cf31205cd971c4e6d",
     "grade": false,
     "grade_id": "exercise5_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pull_next_level(image, weights):\n",
    "    # Prepare ouput.\n",
    "    im_next = np.zeros((image.shape[0] // 2, image.shape[1] // 2, image.shape[2]), dtype=image.dtype)\n",
    "    weights_next = np.zeros((image.shape[0] // 2, image.shape[1] // 2), dtype=weights.dtype)\n",
    "    # TODO: Downscale image to im_next and weights to weights_next as per the exercise description.\n",
    "    # YOUR CODE HERE\n",
    "    return (im_next,  weights_next)\n",
    "    \n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"pyramid\", \"im_02.png\"))\n",
    "weights = helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"pyramid\", \"w_02.png\"))\n",
    "image[weights == 0] = 0\n",
    "\n",
    "im_next, weights_next = pull_next_level(image, weights)\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Input image\": image, \n",
    "    \"Output image (your solution)\": im_next,\n",
    "    \"Input weights\": weights, \n",
    "    \"Output weights (your solution)\": weights_next\n",
    "}, nrows=2, ncols=2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a0a4d97d35b33455deb6b3594f82074",
     "grade": false,
     "grade_id": "cell-5bb05722d14f5915",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 4\n",
    "Verify by hand whether you think your solution to exercise 4 is correct. For example: use your mouse to hover over the input image and write down some pixel values in a small region. Work out the expected output by hand and compare it with what your function produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2e8df183ace49a64387f65b596acad2",
     "grade": true,
     "grade_id": "exercise5",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE, MODIFY, OR COPY THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6efab91273849d645b647599509d577",
     "grade": false,
     "grade_id": "cell-72cd0683db371ff3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Excercise 5 (2 points)\n",
    "Repeat the pull step to build the entire image pyramid. \n",
    "Return a tuple with two lists: images and weight maps, both lists should be sorted from the largest (= the input) to the smallest.\n",
    "Note, that the last level of the pyramid will be a single pixel image $\\mathbf{I}^N \\in \\mathcal{R}^{1 \\times 1 \\times 3}$ and that $\\mathbf{M}^N = 1$. You can again assume that the input is a square image with sides divisible by two.\n",
    "\n",
    "**NOTE**: For grading we use the reference implementation of `pull_next_level()` to ensure that you are not punished for mistakes in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9f852f42cf59543415226e6ef762105",
     "grade": false,
     "grade_id": "execrise6_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_pyramid(image, weights):\n",
    "    pyramid_im = [image]\n",
    "    pyramid_w = [weights]\n",
    "    # TODO: Construct the image- and weights pyramids.\n",
    "    # YOUR CODE HERE\n",
    "    return pyramid_im, pyramid_w\n",
    "\n",
    "\n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"parrots_256.jpg\"))\n",
    "weights = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"parrots_mask_256.png\")) > 0.5).astype(float)\n",
    "image[weights == 0] = 0\n",
    "\n",
    "pyramid_im, pyramid_w = build_pyramid(image, weights)\n",
    "\n",
    "print(\"Your solution:\")\n",
    "panels = { f\"Image #{i}\": im for i, im in enumerate(pyramid_im)}\n",
    "panels.update({ f\"Weights #{i}\": im for i, im in enumerate(pyramid_w)})\n",
    "helpers.show_images(panels, nrows=2, ncols=len(pyramid_im), col_height=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea03cd08e9f30c271f30dee23f2decf7",
     "grade": false,
     "grade_id": "cell-180deea3ef1229da7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 5\n",
    "Verify your solution by hand using the same method as in exercise 5. We provide a couple of basic tests to ensure that you return the values in the correct format for the grading tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bf3b879a865fd5005933e6042e49dd2",
     "grade": true,
     "grade_id": "exercise6",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE, MODIFY, OR COPY THIS CELL\n",
    "\n",
    "import warnings\n",
    "image = np.ones((128, 128, 3))\n",
    "weights = np.zeros((128, 128))\n",
    "weights[62:64, 64:67] = 0\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    image_pyramid, weights_pyramid = build_pyramid(image, weights)\n",
    "assert(len(image_pyramid) == 8) # 128, 64, 32, 16, 8, 4, 2, 1\n",
    "assert(image_pyramid[1].shape == (64, 64, 3))\n",
    "assert(len(weights_pyramid) == 8) # 128, 64, 32, 16, 8, 4, 2, 1\n",
    "assert(weights_pyramid[1].shape == (64, 64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e72d931a22bf4b0e988773bc042bc01c",
     "grade": false,
     "grade_id": "cell-172a22cb105a3ef4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 6 (4 points)\n",
    "The push phase of the algorithm fills the missing pixels $\\mathbf{x}$ in the (larger) lower pyramid level $\\mathbf{I}^{i}$ by bilinear interpolation of the 4 nearest pixels in (smaller) pyramid level $\\mathbf{I}^{i+1}$ above.\n",
    "\n",
    "We first need to find the 4 nearest pixels $A, B, C, D$ which we interpolate to fill the pixel $\\mathbf{x}$.\n",
    "\n",
    "Below you can see how the small pixels in $\\mathbf{I^i}$ (thin blue lines) overlap with large pixels $A,B,C,D$ in $\\mathbf{I^{i+1}}$ (thick black lines):\n",
    "\n",
    "<img src=\"push_grid3.png\" alt=\"Interpolation grid\" style=\"width: 400px;\"/>\n",
    "\n",
    "While pixels are visualized as square patches, for the interpolation it is important to define their exact location. This is typically done by assigning the pixel color to the center of each pixel (see the circles). We can then compute exact position of any point within the pixel grid with subpixel accuracy.\n",
    "\n",
    "### Example\n",
    "In the image above, the point $\\mathbf{x}^{i} = [2.5, 1.5]$ lies in the center of a pixel $\\mathbf{u}^{i} = [2, 1]$ in the high-resolution image $\\mathbf{I}^{i}$. The same point projected to the low-resolution image $\\mathbf{I}^{i+1}$ will have subpixel coordinates $\\mathbf{x}^{i+1} = [1.25, 0.75]$.\n",
    "\n",
    "The point lies within a $2 \\times 2$ neighborhood defined by the centers of pixels A, B, C, D. Subtracting the position of $D$'s center we get a normalized position of the point as $\\mathbf{x}^{i+1}_{norm} = [0.75, 0.25]$ which can then be used for bilinear interpolation.\n",
    "\n",
    "### Task\n",
    "For a given pixel $\\mathbf{u}^{i}$ of the high-resolution image $\\mathbf{I}^{i}$ (yellow pixel in the Figure) and its center  $\\mathbf{x}^{i}$, find the 4 nearest pixels in $\\mathbf{I}^{i+1}$ (see $A, B, C, D$ in the Figure). Return the integer index of the left-top pixel (see $D$) and the relative subpixel position $\\mathbf{x}^{i+1}_{norm}$ within the 4 neighboring points. \n",
    "\n",
    "Note, that knowledge of the image size or content is not required for this exercise.\n",
    "Assume that the image is infinite, i.e., both positive and negative coordinates are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be8b29c9e69ee4db3a0e8782d9396837",
     "grade": false,
     "grade_id": "exercise7_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def project_point_up(px_coordinate_in_down):\n",
    "    index_start = [0, 0]\n",
    "    relative_subpixel_position = [0, 0]\n",
    "    # TODO: Project the point as per the exercise description.\n",
    "    # YOUR CODE HERE\n",
    "    return index_start, relative_subpixel_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f94fa7418f2390708edf5c0abece11d",
     "grade": false,
     "grade_id": "cell-180deea3ef1229a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 6\n",
    "Try to come up with more inputs and work them out by hand. Does your solution produce the correct result for these cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here\n",
    "index_start, relative_subpixel_position = project_point_up(np.array([3, 1]))\n",
    "print(\"Input point [3, 1]\")\n",
    "print(f\"The nearest left-top pixel in the smaller image is {index_start}.\")\n",
    "print(f\"The normalized position is {relative_subpixel_position}.\")\n",
    "print(\"The correct answer should be [1, 0] and [0.25, 0.25]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fde66204646f8200527f9292edac48a",
     "grade": true,
     "grade_id": "exercise7",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE, MODIFY, OR COPY THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7273109989ff8b0d9b0185a088a9eef",
     "grade": false,
     "grade_id": "cell-fbb20375b8ca29cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 7 (2 points)\n",
    "Next, we need to combine the colors from the 4 nearest pixels using bilinear interpolation.\n",
    "\n",
    "Given the 4 nearest pixel color values $\\{\\mathbf{I}^{i}(\\mathbf{A}), \\mathbf{I}^{i}(\\mathbf{B}), \\mathbf{I}^{i}(\\mathbf{C}), \\mathbf{I}^{i}(\\mathbf{D})\\} \\in \\mathcal{R}^{4\\times3}$ and a normalized point position $\\mathbf{x} = (\\alpha, \\beta) \\in [0,1]\\times[0,1]$, compute interpolated value using bilinear interpolation.\n",
    "\n",
    "<img src=\"bilinterp.png\" alt=\"Interpolation grid\" style=\"width: 400px;\"/>\n",
    "\n",
    "Bilinear interpolation is a weighted mean of 4 corner values with weights proportional to areas of rectangle adjacent to each of the source vertices. It can also be separated into 3 one-dimensional linear interpolations by first interpolating the the between $A$ and $B$, and $D$ and $C$ using $\\alpha$ and then interpolating the intermediate results in an orthogonal dimension defined by $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "369221698035a1c2d1468c34b0c9a218",
     "grade": false,
     "grade_id": "exercise8_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bilinear_interpolation(col_a, col_b, col_c, col_d, x):\n",
    "    # TODO: Implement bilinear interpolation between a, b, c, d as shown in the image above. x stores (alpha, beta)\n",
    "    alpha, beta = x\n",
    "    # YOUR CODE HERE\n",
    "    return col_a\n",
    "\n",
    "a = np.array([1.0, 1.0, 1.0])\n",
    "b = np.array([0, 0.0, 1.0])\n",
    "c = np.array([0, 1.0, 0])\n",
    "d = np.array([1.0, 0, 0])\n",
    "x = np.array([0.75, 0.75])\n",
    "\n",
    "interpolated = bilinear_interpolation(a,b,c,d,x)\n",
    "\n",
    "print(f'The interpolated color at {x} was computed as {np.array2string(interpolated, precision=3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c334f016c623ec3220e061edb89f625",
     "grade": false,
     "grade_id": "cell-fc621e575014bcd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 7\n",
    "Try to come up with more inputs and work them out by hand. Does your solution produce the correct result for these cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a4fdac6b796829b48408c9b52d0ac63",
     "grade": true,
     "grade_id": "exercise8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE, MODIFY, OR COPY THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e075a49388fe8747bb085da4d302c772",
     "grade": false,
     "grade_id": "cell-5acac4435d84da61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 8 (4 points)\n",
    "\n",
    "Now we can combine Excercise 6 and 7 together and implement an entire push phase. \n",
    "\n",
    "Implement a method that collapses the image pyramid $\\mathbf{I}^{0..N}$ in the up-down direction and fills missing pixels in each larger high-resolution image $\\mathbf{I}^{i}$ by interpolating a corresponding low-resolution image $\\mathbf{I}^{i+1}$.\n",
    "Do not modify pixels that are marked as valid in the provided weights map $M^{i}$.\n",
    "\n",
    "### Notes\n",
    "Visit every level of the pyramid from the top to the bottom.\n",
    "Test every output pixel and update values of those pixels that are not yet valid. \n",
    "For each such pixel find the 4 neighboring low-resolution pixels and relative pixel position using the code from Exercise 6.\n",
    "Use the relative position as bilinear interpolation weights.\n",
    "Take a special care for pixels that lie close to the image boundary as one of the four neighbors can lie outside of $\\mathbf{I}^{i+1}$. Clamp the coordinates of such neighbor pixel to the domain on $\\mathbf{I}^{i+1}$.\n",
    "\n",
    "**Tip**: look at the image of exercise 7 and how the subpixel coordinates relate to $\\alpha$ and $\\beta$!\n",
    "\n",
    "For grading we use the reference implementation of `project_point_up()` and `bilinear_interpolation` to ensure that you are not punished for mistakes in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "144b8d34771944865c972331f3f8bdb2",
     "grade": false,
     "grade_id": "exercise9_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def push_pyramid(im_pyramid, w_pyramid):\n",
    "    # TODO: Interpolate im_pyramid[i+1] to fill im_pyramid[i] where w_down == 0.\n",
    "    #       Modify im_pyramid in-place (do not edit a copy); this function should **not** return anything.\n",
    "    pass\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "im_files = sorted(helpers.list_files_in_folder(os.path.join(local_data_folder, 'pyramid'), filter=\"im_*.png\"))\n",
    "im_pyramid = [helpers.imread_normalized_float(f) for f in im_files]\n",
    "w_files = sorted(helpers.list_files_in_folder(os.path.join(local_data_folder, 'pyramid'), filter=\"w_*.png\"))\n",
    "w_pyramid = [helpers.imread_normalized_float_grayscale(f) for f in w_files]\n",
    "push_pyramid(im_pyramid, w_pyramid)\n",
    "\n",
    "print(\"Your solution:\")\n",
    "helpers.show_image(im_pyramid[0], title=\"Inpainted (your solution)\")\n",
    "panels = { f\"Image #{i}\": im for i, im in enumerate(im_pyramid)}\n",
    "panels.update({ f\"Weights #{i}\": im for i, im in enumerate(w_pyramid)})\n",
    "helpers.show_images(panels, nrows=2, ncols=len(im_pyramid), col_height=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f3e2685bf63a13a2535b46ab6bb0e15",
     "grade": false,
     "grade_id": "cell-0e6e0695bff91943",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Testing your solution of exercise 8\n",
    "The image pyramid should now not contain any holes anymore. Verify that the interpolated values are correct by creating a simple test case (e.g. 4x4 image that you create yourself) and verify that bilinear interpolation is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aca50be4a85a4873c58b2d482f1f1eb4",
     "grade": true,
     "grade_id": "exercise9",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE, MODIFY, OR COPY THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48bd695b210dfa910ab902ca0942ec99",
     "grade": false,
     "grade_id": "cell-289e2c3a8d7a6166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Full Algorithm\n",
    "Now we have all the necessary components of a complete Pull-Push algorithm and we can use it for image inpainting.\n",
    "In this example we will remove red text caption that has been embedded into a photograph.\n",
    "\n",
    "We recommend you to also try other images and masks. Can you come up with an example where the Pull/Push algorithm doesn't work as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac2ae45c04b1e8ab7fde2b64a86b254c",
     "grade": false,
     "grade_id": "exercise10_code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_red_text(image):\n",
    "    # Detect text.\n",
    "    weights = 1 - np.all(image == [[[1, 0, 0]]], axis=-1)   \n",
    "    # 1. Pull\n",
    "    p_im, p_w = build_pyramid(image, weights)\n",
    "    # 2. Push\n",
    "    push_pyramid(p_im, p_w)\n",
    "    return p_im[0]\n",
    "\n",
    "\n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"image_with_text.png\"))\n",
    "clean_image = remove_red_text(image.copy())\n",
    "\n",
    "panels = { f\"Output #{i}\": im for i, im in enumerate(pyramid_im)}\n",
    "helpers.show_images({\n",
    "    'Input': image,\n",
    "    'Output': clean_image\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d168877113cc28bffc16419230834f84",
     "grade": false,
     "grade_id": "cell-c3ed06cc734f5ded",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Extra Exercises (Patch Based Inpainting)\n",
    "The previous exercises are enough to get you a passing grade. However, to get a $10$ you need to show that you have mastered the topic. Therefore, we introduce the following extra exercises which are considered a bit more challenging. You need to complete these without the help of the teaching assistants (TAs). **You not allowed to ask the TAs for help with the extra exercises**. However, you can report bugs by sending us an e-mail at `vdp-cs-ewi@tudelft.nl`.\n",
    "\n",
    "With pull-push you have implemented an inpainting technique based on low-level statistics. In the following extra exercises you will implement (a part of) the patch based inpainting technique from the paper [Region filling and object removal by exemplar-based image inpainting](https://www.irisa.fr/vista/Papers/2004_ip_criminisi.pdf) which was also described in class. The idea is to take patches (small square regions) from the known image and paste them into the missing pixels. The challenge is to find the most suitable patch and to fill pixels in an appropriate order.\n",
    "\n",
    "<img src=\"images/canyonlakedrive.jpg\" alt=\"Hollywood Sign\" style=\"height: 25em;\"/>\n",
    "\n",
    "### Selecting the next patch to fill\n",
    "We are given an image $J$ with unknown pixels defined by a second mask image, similar to the previous exercises (with $1$ for known pixels and $0$ for unknown pixels). To select the next region to inpaint we consider the unknown pixels on the boundary between the known/unknown regions of the image. For each of those pixels we consider filling the patch centered at that pixel. We select the patch to fill by maximizing the following equation:\n",
    "\n",
    "$$P(p) = C(p) * D(p)$$\n",
    "\n",
    "The data term $D(p)$ prefers selecting patches such that edges or lines in the image are inpainted first, before inpainting more flat/uniform regions. The data term is defined as the length of the projection of the isophote (edge/line in the image) and the normal vector of the inpainting boundary. The isophote is orthogonal to the gradient with the highest magnitude between known pixels in the patch. The normal vector of the known/unknown region boundary is computed by taking the difference between the current boundary pixel and the next boundary pixel.\n",
    "\n",
    "<img src=\"images/data_term.png\" alt=\"Data Term\" style=\"height: 25em;\"/>\n",
    "\n",
    "When inpainting we continuously select a patch on the boundary of the unknown region, fill it by copy & pasting values from another patch, and continue untill the whole image is filled. We cannot be sure however that the colours that we picked to fill preceding patches accurately represent what was supposed to be there. Therefore, our confidence in the value of those pixels, and thus the data term, drops. This confidence in each pixel's value at step $k$ is stored in a confidence image $C_k(q)$ which, like the image mask, starts as $C_0(q)$ with $1.0$ for all known pixels (100% confident) and $0.0$ for unknown pixels. The confidence value $C_k(p)$ is defined as the mean $C_{k-1}(q)$ value for all pixels inside the patch. When a patch centered at pixel $p$ is selected for inpainting in step $k$, the confidence values $C_k(q)$ of unknown pixels in the patch are updated to the confidence value $C_{k-1}(p)$ from the previous step.\n",
    "\n",
    "<img src=\"images/confidence_term.png\" alt=\"Confidence Term\" style=\"height: 25em;\"/>\n",
    "\n",
    "\n",
    "### Exercise 9 (1 point)\n",
    "You will implement a function that computes the confidence term $C_k(p)$ for a given patch as described above (and in the lecture). Your function takes the confidence image $C_{k-1}(p)$, the pixel at the center of the patch, and the patch size. You can use the helper function `slice_patch` to get the patch from an image. You do not need to handle patches that lie (partially) outside the image; we guarantee that no such patches will be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a00ba2c6a38086af831b346080c04f6c",
     "grade": false,
     "grade_id": "cell-a7741ff6aefbc3f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "def slice_patch(image, x, y, patch_size):\n",
    "    half_patch_size = patch_size // 2\n",
    "    return image[y-half_patch_size:y+half_patch_size+1, x-half_patch_size:x+half_patch_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66457d94f122d8509b75b60d38b86f88",
     "grade": false,
     "grade_id": "cell-b6d1fce3e4dc1cef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_confidence_term(confidence_image, x, y, patch_size):\n",
    "    # TODO: Compute the confidence term of the image patch with the given size and centered at (x, y)\n",
    "    # YOUR CODE HERE\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd789d04641dcbbec6d83c13f61ed67e",
     "grade": false,
     "grade_id": "cell-2f8dfcb585dc73b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Testing your solution of exercise 9\n",
    "Try to come up with some test cases (e.g. images) to ensure your solution is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"canyonlakedrive.jpg\"), 0.35)\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"canyonlakedrive_mask.png\"), 0.35) < 0.5)\n",
    "image[mask == 0] = 0\n",
    "\n",
    "# Compute boundary pixels\n",
    "confidence_image_cq = mask.copy()\n",
    "confidence_term_cp = np.zeros(mask.shape)\n",
    "patch_size = 9\n",
    "for y, x in zip(*np.where(mask == 0)):\n",
    "    if np.sum(image[y-1:y+2,x-1:x+2]) > 0:\n",
    "        confidence_term_cp[y, x] = compute_confidence_term(confidence_image_cq, x, y, patch_size)\n",
    "\n",
    "helpers.show_images({\n",
    "    'Confidence Image $C_{k-1}(q)$': mask,\n",
    "    'Confidence Term $C_k(p)$': confidence_term_cp\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed00c853650feb439898132cae6d53c2",
     "grade": true,
     "grade_id": "cell-40b3a81f6fe15fbf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE, MODIFY, OR COPY THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad2600097636b86626fee68d281794b8",
     "grade": false,
     "grade_id": "cell-ee2e65479459b721",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Fill Front\n",
    "In order to compute the data term $D(p)$ we need to define the normal vector of the boundary. This is computed by comparing the current boundary pixel position to its neighbours positions. The following provided code computes the list of pixels on the boundary of the known/unknown region in clock wise order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b068853ebdecdbcbecd53121bef62369",
     "grade": false,
     "grade_id": "cell-84c8949caecf9237",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find all boundary pixels (fill front) in clock wise order (must be sorted to compute data term)\n",
    "def compute_fill_front(target_mask):\n",
    "    # If there are no pixels to fill then we are done.\n",
    "    if np.sum(1 - target_mask) == 0:\n",
    "        return []\n",
    "    \n",
    "    # We need to find a starting point. We find an unknown pixel which might be a boundary pixel but could also lie deeper in the unknown region.\n",
    "    # So we visit all pixels in that row (same y coordinate) from left to right to find the first boundary pixel.\n",
    "    first_y, _ = next(zip(*np.where(target_mask == 0)))\n",
    "    for first_x in range(target_mask.shape[1]):\n",
    "        if target_mask[first_y, first_x] == 0:\n",
    "            break\n",
    "    \n",
    "    fill_front = [] # Sorted output\n",
    "    visited_pixels = set() # Contains the currently visited set of pixels (same as fill front but a set() instead of list() for faster lookups)\n",
    "    \n",
    "    # The potential neighbours to consider (relative to the current pixel) in *clockwise* order.\n",
    "    directions = [(-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0)]\n",
    "    current_direction = 0 # Current direction that we are following along the boundary\n",
    "    x, y = first_x, first_y # x and y coordinates of the current boundary pixel\n",
    "    done = False # Track whether we are done (finished the circle)\n",
    "    while not done:\n",
    "        # Add the current boundary pixel to the output\n",
    "        fill_front.append((x, y))\n",
    "        visited_pixels.add((x, y))\n",
    "        \n",
    "        # Start by trying to go backwards (current_direction + 4) and from there visit the neighbours in clockwise order.\n",
    "        done = True\n",
    "        direction = current_direction + 4\n",
    "        for i in range(len(directions)):\n",
    "            dx, dy = directions[(direction + i) % len(directions)]\n",
    "            nx, ny = x + dx, y + dy\n",
    "            # A pixel is a boundary pixel if its value is unknown and at least one of its (8 connected) neighbours is known.\n",
    "            is_neighbour_on_boundary = np.sum(target_mask[ny-1:ny+2,nx-1:nx+2]) > 0 and target_mask[ny, nx] == 0\n",
    "            if is_neighbour_on_boundary and (nx, ny) not in visited_pixels: # Skip neighbours that we've already visited\n",
    "                x, y = nx, ny # Visit the neighbour\n",
    "                current_direction = (direction + i) % len(directions)\n",
    "                done = False # We visited a new neighbour so we are not done yet\n",
    "                break # Stop the clockwise visiting and go to the neighbour we just selected\n",
    "    \n",
    "    return fill_front\n",
    "\n",
    "\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"line_mask.png\"), 1) > 0.5)\n",
    "fill_front = compute_fill_front(mask)\n",
    "\n",
    "image = np.zeros(mask.shape)\n",
    "for i, (x, y) in enumerate(fill_front):\n",
    "    image[y, x] = i / len(fill_front)\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Known/unknown pixels mask\": mask,\n",
    "    \"Fill Front / boundary\": image\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c279f78899171c9cc81a2630f945f8e6",
     "grade": false,
     "grade_id": "cell-e5b156781be3ee6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Exercise 10 (4 points)\n",
    "Complete the given function which takes a list of pixels along the fill front (to compute the normal) and computes for each of those pixels the data term $D(p)$. Refer to the description above the previous exercise, or the lecture slides, for more information on how to compute the data term.\n",
    "\n",
    "*Tip*: remember that the isophote is parallel to an edge and not orthognal like a gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "772f1a086407a398d8edb17fb6507f97",
     "grade": false,
     "grade_id": "cell-753cbbe72dd680cc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    return np.array(v) / np.linalg.norm(v)\n",
    "\n",
    "def compute_data_term_along_fill_front(image, target_mask, patch_size, fill_front):\n",
    "    gray_image = helpers.rgb2gray(image)    \n",
    "    gradient_x = scipy.signal.correlate2d(gray_image, [[-0.5, 0, +0.5]], mode=\"same\", boundary=\"symm\")\n",
    "    gradient_y = scipy.signal.correlate2d(gray_image, [[-0.5], [0], [+0.5]], mode=\"same\", boundary=\"symm\")\n",
    "    \n",
    "    # Mask out pixels for which a neighbour is unknown (and thus the gradient is invalid)\n",
    "    grown_mask = 1 - (scipy.signal.correlate2d(1-target_mask, [[0,1,0], [1,0,1],[0,1,0]], mode=\"same\") > 0)\n",
    "    gradient_x *= grown_mask\n",
    "    gradient_y *= grown_mask\n",
    "    \n",
    "    out = []\n",
    "    for (xl, yl), (x, y), (xr, yr) in zip(fill_front[-1:] + fill_front[:-1], fill_front, fill_front[1:] + fill_front[:1]):\n",
    "        # Normal of the boundary.\n",
    "        n_p = normalize([yl-yr, xr-xl]) # (xr-xl, yr-yl) is parallel to the boundary; (-(yr-yl), xr-xl) is orthogonal to the boundary.\n",
    "    \n",
    "        # ======================\n",
    "        # === ADD CODE BELOW ===\n",
    "        # ======================\n",
    "        # For the patch of patch_size around the pixel (x, y) (as returned by the slice_patch() method),\n",
    "        #  compute the isophote using the highest magnitude gradient within the patch (according to the L2 norm).\n",
    "        # Remember that the isophote is not the gradient itself, but orthognal to the gradient.\n",
    "        # Use the isophote and normal of the boundary (computed above) to compute the data term D(p) and store the result in the variable \"D_p\".\n",
    "        D_p = 0.0\n",
    "        # YOUR CODE HERE\n",
    "        out.append(D_p)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a1fa3f2c70c8c531281335548632d80",
     "grade": false,
     "grade_id": "cell-b0438220188e2934",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Testing your solution of exercise 10\n",
    "The following code displays the data term for the whole image. The data term values are multiplied by three to increase visibility. Try to come up with some additional test cases (images) to convince yourself that your solution is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"canyonlakedrive.jpg\"), 0.35)\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"canyonlakedrive_mask.png\"), 0.35) < 0.5)\n",
    "image[mask == 0] = 0\n",
    "\n",
    "patch_size = 9\n",
    "\n",
    "fill_front = compute_fill_front(mask)\n",
    "fill_front = [(x, y) for x, y in fill_front if x > 3 and y > 3]\n",
    "data_term_on_fill_front = compute_data_term_along_fill_front(image, mask, patch_size, fill_front)\n",
    "\n",
    "# Create an image showing the value of D(p) along the fill front / boundary\n",
    "data_term_image = np.zeros(mask.shape)\n",
    "for (x, y), D_p in zip(fill_front, data_term_on_fill_front):\n",
    "    data_term_image[y, x] = D_p\n",
    "\n",
    "helpers.show_images({\n",
    "    'Input': image,\n",
    "    '3x Data Term ($3 \\cdot D(p)$)': data_term_image * 3\n",
    "}, nrows=1, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a13f819bfc5a7757998bacd1c86893f",
     "grade": true,
     "grade_id": "cell-a821eefb7ccece9a",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE, MODIFY, OR COPY THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "182a4f21bc7bacd8c22fc697a7895b14",
     "grade": false,
     "grade_id": "cell-141f80a3604949b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Finding a matching patch\n",
    "Once a *query* patch has been selected for inpainting (using product of the confidence & data terms) we now need to find new values to assign to the unknown pixels inside the query patch. The algorithm is based on the idea of copy & pasting patches from other (known) parts of the image. All *complete* patches (patches fully inside the image with no unknown pixels) are visited and compared to the *query* patch and the most similar one is selected.\n",
    "\n",
    "Similarity between a *query* patch and the complete patches is defined the negated sum of squared differences over the *known* pixels. Unknown pixels (that need to be filled in) should be excluded from this sum:\n",
    "$$\n",
    "\\text{similarity}({query}, {compare}) = -\\sum_{i \\in \\text{known pixels/color channels in query}}{({query}_i - {compare}_i)^2}\n",
    "$$\n",
    "\n",
    "### Exercise 11 (4 points)\n",
    "Implement a function that searches the image for the most similar *complete* patch for the given *query* patch. Return the center pixel of this selected patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fa12618952ce8cabdc0c384a046bce7",
     "grade": false,
     "grade_id": "exercise11_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "def find_most_similar_patch(image, target_mask, query_x, query_y, patch_size):\n",
    "    x = 10\n",
    "    y = 10\n",
    "    # TODO: Iterate over all patches in the image that have only known pixels\n",
    "    #       Compute the similarity between \n",
    "    # YOUR CODE HERE\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fffaf5ed941973cc2639f2fc6d6a0d4",
     "grade": false,
     "grade_id": "cell-43f9e7ef9b3ececd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Testing your solution of exercise 11\n",
    "The following code displays a query patch and the most similar patch as found by your implementation. Try to come up with some additional test cases (patches) to convince yourself that your solution is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own tests here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"canyonlakedrive.jpg\"), 0.35)\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"canyonlakedrive_mask.png\"), 0.35) < 0.5)\n",
    "image[mask == 0] = 0\n",
    "\n",
    "patch_size = 9\n",
    "half_patch_size = patch_size // 2\n",
    "\n",
    "query_pixels = list(zip(*np.where(mask == 0)))\n",
    "query_y, query_x = query_pixels[0] # TRY OUT DIFFERENT QUERY PIXELS BY CHANGING THIS NUMBER\n",
    "match_x, match_y = find_most_similar_patch(image, mask, query_x, query_y, patch_size)\n",
    "\n",
    "helpers.show_images({\n",
    "    \"Query patch\": slice_patch(image, query_x, query_y, patch_size),\n",
    "    \"Most similar complete patch (your solution)\": slice_patch(image, match_x, match_y, patch_size),\n",
    "    \"Absolute Pixel Differences:\": slice_patch(mask, query_x, query_y, patch_size) * np.mean(np.abs(slice_patch(image, query_x, query_y, patch_size) - slice_patch(image, match_x, match_y, patch_size)), axis=2)\n",
    "}, ncols=3, nrows=1)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1)\n",
    "ax1.set_title(\"Query Patch (Red); Most Similar Patch (Cyan)\")\n",
    "ax1.imshow(image)\n",
    "ax1.add_patch(patches.Rectangle((query_x - half_patch_size, query_y - half_patch_size), patch_size, patch_size, fill=False, edgecolor=\"red\", linewidth=3))\n",
    "ax1.add_patch(patches.Rectangle((match_x - half_patch_size, match_y - half_patch_size), patch_size, patch_size, fill=False, edgecolor=\"cyan\", linewidth=3))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdac9846799aad5c0d3e66418f00baf4",
     "grade": true,
     "grade_id": "exercise11",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE, MODIFY, OR COPY THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d88a1e32b61cd920594ed9d093976ea",
     "grade": false,
     "grade_id": "cell-cfa64c8349dcf864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Inpainting\n",
    "With the exercises implemented it is now possible to run the complete inpainting algorithm. In a continuous loop the highest priority patch is selected (exercises 9 & 10), the most similar complete image patch is found (exercise 11) and values from that patch are pasted into the unknown pixels of the selected query patch. Finally the unknown pixels in the confidence image $C_k(p)$ is updated from the value of $C_{k-1}(p)$.\n",
    "\n",
    "The full inpainting algorithm is implemented below and should succesfully remove the Hollywood sign from Mount Lee. The inpainting process is visualized interactively: the image is updated after each step. Don't worry if it takes a couple minutes to perform the inpainting; this is not part of the grading tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd816e2063eaa7dec425c5bc27c3a2ed",
     "grade": false,
     "grade_id": "cell-20e92b7a9e9fb0ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from IPython import display\n",
    "import os\n",
    "\n",
    "def select_highest_priority_patch(image, confidence_image, target_mask, fill_front, patch_size):\n",
    "    confidence_term = [compute_confidence_term(confidence_image, x, y, patch_size) for x, y in fill_front]\n",
    "    data_term = compute_data_term_along_fill_front(image, target_mask, patch_size, fill_front)\n",
    "    priority = np.array(confidence_term) * np.array(data_term)\n",
    "    selected_index = np.argmax(priority)\n",
    "    return (fill_front[selected_index], confidence_term[selected_index])\n",
    "\n",
    "def patch_based_inpainting(image, target_mask, patch_size):\n",
    "    confidence_image = np.zeros(target_mask.shape)\n",
    "    confidence_image[mask == 0] = 1\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    fig.show()\n",
    "    \n",
    "    num_pixels_to_fill = np.sum(1 - target_mask)\n",
    "    image = image.copy()\n",
    "    with progressbar.ProgressBar(maxval = num_pixels_to_fill) as bar:\n",
    "    #with progressbar.ProgressBar(max_value = num_pixels_to_fill) as bar:\n",
    "        while True:\n",
    "            bar.update(num_pixels_to_fill - np.sum(1 - target_mask)) # Number of pixels that have not been filled yet.\n",
    "            fill_front = compute_fill_front(target_mask)\n",
    "            if not fill_front:\n",
    "                break\n",
    "\n",
    "            (x, y), confidence = select_highest_priority_patch(image, confidence_image, target_mask, fill_front, patch_size+4)\n",
    "            qx, qy  = find_most_similar_patch(image, target_mask, x, y, patch_size)\n",
    "            mask_patch = slice_patch(target_mask, x, y, patch_size)\n",
    "            out_patch = slice_patch(image, x, y, patch_size)\n",
    "            in_patch = slice_patch(image, qx, qy, patch_size)\n",
    "            for dy in range(patch_size):\n",
    "                for dx in range(patch_size):\n",
    "                    if mask_patch[dy, dx] == 0:\n",
    "                        out_patch[dy, dx, :] = in_patch[dy, dx, :]\n",
    "            slice_patch(confidence_image, x, y, patch_size)[:] = confidence\n",
    "            mask_patch[:] = 1 # Set the mask to 1 pixels in the patch\n",
    "\n",
    "            ax.imshow(image, interpolation=\"None\")\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(fig)\n",
    "        \n",
    "    return image\n",
    "\n",
    "\n",
    "image = helpers.imread_normalized_float(os.path.join(local_data_folder, \"canyonlakedrive.jpg\"), 0.35)\n",
    "mask = (helpers.imread_normalized_float_grayscale(os.path.join(local_data_folder, \"canyonlakedrive_mask.png\"), 0.35) < 0.5)\n",
    "original_image = image.copy()\n",
    "image[mask == 0] = 0\n",
    "# Don't execute the inpainting algorithm when grading\n",
    "if os.environ.get(\"NBGRADER_EXECUTION\") != \"autograde\" and os.environ.get(\"NBGRADER_EXECUTION\") != \"validate\":\n",
    "    clean_image = patch_based_inpainting(image, mask, 9)\n",
    "\n",
    "helpers.show_images({\n",
    "    'Input': original_image,\n",
    "    'Output': clean_image\n",
    "}, nrows=1, ncols=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e23ee5192b0758591530755eb1daadb41813c448255c459cb26f125197f59a99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
